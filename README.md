# ğŸ’¬ Gemini Chatbot

A smart, conversational chatbot powered by **Google Gemini Pro** with **semantic memory** using **Chroma vector store** and **LangChain**. Designed with a clean **Streamlit UI**, it supports multiple chat sessions, memory recall, and a professional welcome experience.

---

## ğŸš€ Features

* ğŸ” **Semantic memory with ChromaDB**: Retrieves previous messages similar to your current question.
* ğŸ§  **Gemini Pro API**: Powered by Googleâ€™s latest language model.
* ğŸ’¬ **Multi-session support**: Start new chats, view past ones in the sidebar.
* ğŸ¨ **Streamlit UI**: Modern, responsive chat interface.
* ğŸ“ **Welcome prompt**: Personalized message when starting a new conversation.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ chat.py           # Handles chatbot response logic
â”‚   â”œâ”€â”€ memory.py         # Vectorstore-based memory storage/retrieval
â”‚   â””â”€â”€ config.py         # (optional) API key or settings management
â”œâ”€â”€ chroma_chat_memory/   # Chroma's vector database directory
â”œâ”€â”€ streamlit_app.py      # Main Streamlit UI
â”œâ”€â”€ main.py               # Optional CLI interface
â”œâ”€â”€ Dockerfile            # Docker container build instructions
â”œâ”€â”€ docker-compose.yml    # Optional: used earlier with Redis
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project info
```

---

## âš™ï¸ Setup Instructions

### 1. ğŸ”‘ Configure API Key

Create a `.env` file and add your [Gemini API key](https://makersuite.google.com/app/apikey):

```
GOOGLE_API_KEY=your_api_key_here
```

Or export it in your environment:

```bash
export GOOGLE_API_KEY=your_api_key_here
```

---

### 2. ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

Ensure these are in your `requirements.txt`:

```txt
streamlit
langchain
langchain-community
google-generativeai
chromadb
streamlit-extras
```

---

### 3. ğŸ§ª Run the App

```bash
streamlit run streamlit_app.py
```

Then open `http://localhost:8501` in your browser.

---

## ğŸ³ Docker (Optional)

If you want to run in a container:

1. **Build the image**

```bash
docker build -t gemini-chatbot .
```

2. **Run the container**

```bash
docker run -p 8501:8501 --env-file .env gemini-chatbot
```

---

## ğŸ›  How It Works

* Each user message is embedded using **GoogleGenerativeAIEmbeddings**
* Stored in **Chroma vector store**
* When a user asks a new question:

  * Recent, similar messages are retrieved
  * Used as **context** for Geminiâ€™s next response
* The result is a more memory-aware chatbot with better continuity


